#### Немного питоновских библиотек:
1) [[PyTorch]]

#### Алгоритмы кластеризации:
1) [[K-means]]

#### Бустинги:
1) [[AdaBoost]]
2) [[GBM]]

[[Строение нейрона]]
#### Типы нейронов:
1) линейные (чекай [[Перцептроны]])
2) [[Сигмоидальные]]
3) [[С гиперболическим тангенсом]]
4) [[ReLu]]
5) и его друг [[Softplus]]
6) [[Softmax]]
7) 

#### Слои нейронных сетей:
1) [[Перцептроны]]
3) [[CNN]]
4) [[Pooling]]

#### Регуляризация 
1) [[L1&L2]]
2) [[Dropout]]

#### Эволюция сверточных сетей
1) [[LeNet]] (самая первая и примитивная)\
2) [[AlexNet]] (чуть сложнее)
3) [[VGG]] Network ( состоит из блоков, каждый из которых состоит из нескольких слоев сверток и макспулинга)
4) [[NiN]]
5) [[ResNet]]
6) [[ResNeXt]]

#### Состав метрики:
1) [[Функция потерь]]
2) [[Эмпирический риск]]

#### Методы оптимизации:
1) sgd
2) [[sgd with momentum]]
3) [[sgd with nesterov momentum]]
4) [[adagrad]]
5) [[rmsprop]]
6) [[adam]]
7) [[adadelta]]


#### Термины и обозначения дип лернинга: 
1) [[Лютейшая база]] 
2) [[Батч]]
3) [[Эпоха]]

#### Backpropagation:
1) [[Лютейшая база]]
2) [[Два предположения, нужных для функции эмпирического риска]]
3) [[Hadamard product]]
4) [[Четыре базовых уравнения для backpropagation]]


#### Метрики (и им подобные):
1) [[OLS]]
2) [[MLE]]
3) [[Cross Entropy Loss]]

#### Honorable mentions:
1) [[Bottle]]